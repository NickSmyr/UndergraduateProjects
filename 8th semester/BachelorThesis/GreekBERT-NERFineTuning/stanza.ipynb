{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from conllu import parse_incr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/master/resources_1.2.0.json: 128kB [00:00, 5.97MB/s]                    \n",
      "2021-05-10 15:14:20 INFO: Downloading these customized packages for language: el (Greek)...\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| depparse  | gdt     |\n",
      "| pretrain  | gdt     |\n",
      "=======================\n",
      "\n",
      "2021-05-10 15:14:21 INFO: File exists: /home/sm/stanza_resources/el/depparse/gdt.pt.\n",
      "2021-05-10 15:14:21 INFO: File exists: /home/sm/stanza_resources/el/pretrain/gdt.pt.\n",
      "2021-05-10 15:14:21 INFO: Finished downloading models and saved to /home/sm/stanza_resources.\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/master/resources_1.2.0.json: 128kB [00:00, 4.64MB/s]                    \n",
      "2021-05-10 15:14:22 INFO: Downloading these customized packages for language: el (Greek)...\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| lemma     | gdt     |\n",
      "=======================\n",
      "\n",
      "2021-05-10 15:14:22 INFO: File exists: /home/sm/stanza_resources/el/lemma/gdt.pt.\n",
      "2021-05-10 15:14:22 INFO: Finished downloading models and saved to /home/sm/stanza_resources.\n"
     ]
    }
   ],
   "source": [
    "import stanza\n",
    "stanza.download('el',processors='depparse')\n",
    "stanza.download(lang=\"el\",package=None,processors={\"lemma\":\"gdt\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-10 17:52:05 INFO: Loading these models for language: el (Greek):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | gdt     |\n",
      "| mwt       | gdt     |\n",
      "| pos       | gdt     |\n",
      "=======================\n",
      "\n",
      "2021-05-10 17:52:05 INFO: Use device: cpu\n",
      "2021-05-10 17:52:05 INFO: Loading: tokenize\n",
      "2021-05-10 17:52:05 INFO: Loading: mwt\n",
      "2021-05-10 17:52:05 INFO: Loading: pos\n",
      "2021-05-10 17:52:06 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "# UD\n",
    "nlp = stanza.Pipeline(lang='el', processors='tokenize,mwt,pos', use_gpu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"./data/ud/train.conllu\"\n",
    "texts = []\n",
    "total_tokens = 0\n",
    "with open(filename) as f:\n",
    "    for sent in parse_incr(f):\n",
    "        token_forms = []\n",
    "        for x in sent:\n",
    "            token_forms.append(x['form'])\n",
    "            total_tokens +=1\n",
    "        sentence = \" \".join(token_forms)\n",
    "        texts.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43440\n"
     ]
    }
   ],
   "source": [
    "print(total_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "def measure(func, times=10):\n",
    "    durations = [] \n",
    "    for x in tqdm(list(range(times))):\n",
    "        start = time.time()\n",
    "        func()\n",
    "        end = time.time()\n",
    "        dur = end - start\n",
    "        durations.append(dur)\n",
    "        \n",
    "    return durations\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stanza_perf_run():\n",
    "    for x in texts:\n",
    "        doc = nlp(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee93054c8e1446bda27dc25abce32963",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[155.73975777626038,\n",
       " 159.30799102783203,\n",
       " 145.27961087226868,\n",
       " 158.21757221221924,\n",
       " 149.8651442527771,\n",
       " 151.58325481414795,\n",
       " 155.58528017997742,\n",
       " 155.9983742237091,\n",
       " 144.66025614738464,\n",
       " 148.94389009475708]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measure(stanza_perf_run , 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "stanza_times = [155.73975777626038,\n",
    " 159.30799102783203,\n",
    " 145.27961087226868,\n",
    " 158.21757221221924,\n",
    " 149.8651442527771,\n",
    " 151.58325481414795,\n",
    " 155.58528017997742,\n",
    " 155.9983742237091,\n",
    " 144.66025614738464,\n",
    " 148.94389009475708]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "secs = mean(stanza_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "284.81862973475836"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_tokens / secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"nlpaueb/bert-base-greek-uncased-v1\")\n",
    "model = AutoModel.from_pretrained(\"nlpaueb/bert-base-greek-uncased-v1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 8299, 351, 1284, 3310, 108, 102]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"Καλησπέρα με λένε Νίκο!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from examples.ud.bert_mtask.model import UDBERTMTASKModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from examples.multitask.dpud.model import POSDPModel\n",
    "import pickle\n",
    "import torch\n",
    "deprel_i2l = None\n",
    "with open('deprel_i2l.pickle', 'rb') as f:\n",
    "    deprel_i2l = pickle.load(f)\n",
    "        \n",
    "path = 'ud_features_I2L.pickle'\n",
    "feat_to_I2L = None\n",
    "\n",
    "with open(path, 'rb') as f:\n",
    "    feat_to_I2L = pickle.load(f)\n",
    "            \n",
    "feat_to_size = {k: len(v) for k, v in feat_to_I2L.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_head = POSDPModel(model, deprel_i2l, feat_to_size, 0.1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_head = UDBERTMTASKModel(model, feat_to_size , 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  101, 28619, 12634, 12634,   182,   102]])\n"
     ]
    }
   ],
   "source": [
    "sent = \"taxaxaxa\"\n",
    "tens = tokenizer.encode(sent , return_tensors=\"pt\")\n",
    "lens = torch.Tensor(tens.shape[1]) \n",
    "print(tens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gbertfrom_configerf_run():\n",
    "    for x in texts:\n",
    "        with torch.no_grad():\n",
    "            tens = tokenizer.encode(x , return_tensors=\"pt\")\n",
    "            lens = torch.Tensor([tens.shape[1]]) \n",
    "            prds = model_head(tens,lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6763e515058c4f928b4b81622009aebd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[103.3727195262909,\n",
       " 96.21718382835388,\n",
       " 107.85014271736145,\n",
       " 97.03432655334473,\n",
       " 94.23229169845581,\n",
       " 93.75064587593079,\n",
       " 94.41303515434265,\n",
       " 93.04832005500793,\n",
       " 92.91282320022583,\n",
       " 93.53021121025085]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measure(gbertfrom_configerf_run , times=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "durs= [103.3727195262909,\n",
    " 96.21718382835388,\n",
    " 107.85014271736145,\n",
    " 97.03432655334473,\n",
    " 94.23229169845581,\n",
    " 93.75064587593079,\n",
    " 94.41303515434265,\n",
    " 93.04832005500793,\n",
    " 92.91282320022583,\n",
    " 93.53021121025085]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = mean(durs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "449.52112659381"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_tokens / m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
